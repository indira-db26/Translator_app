<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lingofy AI Playground</title>
    <!-- Load Firebase/Firestore Modules -->
    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, signInAnonymously, signInWithCustomToken, onAuthStateChanged } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, doc, setDoc, getDoc, onSnapshot } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";
        import { setLogLevel } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";
        
        // Expose Firebase functions to the global scope for use in non-module script
        window.firebase = { 
            initializeApp, 
            getAuth, 
            signInAnonymously, 
            signInWithCustomToken, 
            onAuthStateChanged,
            getFirestore, 
            doc, 
            setDoc, 
            getDoc, 
            onSnapshot,
            setLogLevel 
        };
    </script>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load Lucide Icons -->
    <script src="https://unpkg.com/lucide@latest"></script>
    <style>
        /* Custom Styles for Interactivity and Design */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7f9fc;
        }
        .container-card {
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.1);
        }
        .translate-button:active {
            transform: scale(0.98);
        }
        .tab-active {
            border-bottom: 3px solid #4f46e5; /* indigo-600 */
            color: #4f46e5;
            font-weight: 600;
        }
        @keyframes spin-once {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }
        .animate-spin-once {
            animation: spin-once 0.3s ease-in-out;
        }
        .output-container {
            min-height: 12rem;
        }
        .recording-pulse {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
    </style>
</head>
<body class="min-h-screen p-4 sm:p-8 flex items-center justify-center">

    <div id="app" class="w-full max-w-5xl bg-white rounded-xl container-card p-6 sm:p-10">
        <!-- Header -->
        <h1 class="text-4xl font-extrabold text-indigo-700 mb-2 flex items-center">
            <i data-lucide="award" class="w-8 h-8 mr-3 text-emerald-500"></i>
            Lingofy AI Playground
        </h1>
        <p class="text-gray-500 mb-6">Master translation with Text, Image, and Voice modes. Now supporting Indian languages!</p>

        <!-- Stats and User ID -->
        <div class="flex flex-col sm:flex-row justify-between items-center mb-6 p-4 bg-indigo-50 rounded-lg border border-indigo-200">
            <div class="flex space-x-6">
                <div class="text-center">
                    <p class="text-xs font-medium text-gray-500">Total Translations</p>
                    <p id="total-translations" class="text-2xl font-bold text-indigo-600">--</p>
                </div>
                <div class="text-center">
                    <p class="text-xs font-medium text-gray-500">Current Streak</p>
                    <p id="current-streak" class="text-2xl font-bold text-emerald-600">--</p>
                </div>
            </div>
            <div class="mt-4 sm:mt-0 text-xs text-gray-500 truncate max-w-full">
                <p>User ID: <span id="user-id" class="font-mono text-gray-700">Loading...</span></p>
            </div>
        </div>

        <!-- Mode Selector (Tabs) -->
        <div class="flex border-b mb-6">
            <button id="mode-text" class="px-4 py-2 text-gray-500 hover:text-indigo-600 transition tab-active">
                <i data-lucide="pencil" class="w-4 h-4 inline mr-1"></i> Text
            </button>
            <button id="mode-image" class="px-4 py-2 text-gray-500 hover:text-indigo-600 transition">
                <i data-lucide="image" class="w-4 h-4 inline mr-1"></i> Image
            </button>
            <button id="mode-voice" class="px-4 py-2 text-gray-500 hover:text-indigo-600 transition">
                <i data-lucide="mic" class="w-4 h-4 inline mr-1"></i> Voice
            </button>
        </div>

        <!-- Language Selector Row -->
        <div class="flex flex-col sm:flex-row items-center justify-between mb-6 space-y-4 sm:space-y-0 sm:space-x-4">
            <!-- Source Language -->
            <div class="flex-1 w-full">
                <label for="source-lang" class="text-sm font-medium text-gray-700 block mb-1">Source Language</label>
                <select id="source-lang" class="w-full p-2.5 border border-indigo-300 rounded-lg focus:ring-indigo-500 focus:border-indigo-500 transition duration-150"></select>
            </div>
            
            <!-- Swap Button -->
            <button id="swap-btn" class="swap-button p-2 bg-indigo-100 rounded-full text-indigo-700 hover:bg-indigo-200 transition-all duration-300">
                <i data-lucide="switch-horizontal" class="w-6 h-6"></i>
            </button>
            
            <!-- Target Language -->
            <div class="flex-1 w-full">
                <label for="target-lang" class="text-sm font-medium text-gray-700 block mb-1">Target Language</label>
                <select id="target-lang" class="w-full p-2.5 border border-indigo-300 rounded-lg focus:ring-indigo-500 focus:border-indigo-500 transition duration-150"></select>
            </div>
        </div>
        
        <!-- Main Content Area -->
        <div class="grid grid-cols-1 lg:grid-cols-2 gap-6">
            <!-- Input Card (Dynamic based on mode) -->
            <div class="bg-indigo-50 p-4 rounded-xl border border-indigo-200 output-container flex flex-col">
                <label id="input-label" class="font-bold text-indigo-700 mb-2">Enter Text</label>

                <!-- Shared Text Input for all modes -->
                <textarea id="input-text" 
                          class="w-full flex-grow p-3 bg-white border border-indigo-300 rounded-lg resize-none focus:outline-none focus:ring-2 focus:ring-indigo-500"
                          placeholder="Type or use the file/voice input below..."
                          maxlength="1000"></textarea>
                <span id="char-count" class="text-xs text-gray-500 mt-2 self-end">0 / 1000 characters</span>

                <!-- Input Controls (Adapts to mode) -->
                <div id="input-controls" class="mt-3 flex flex-col space-y-3">
                    <!-- Image Input -->
                    <div id="image-control" class="flex-col items-center hidden">
                        <input type="file" id="image-upload" accept="image/jpeg,image/png,image/webp" class="mb-2 p-2 w-full border border-indigo-300 rounded-lg bg-white text-sm">
                        <img id="image-preview" class="max-w-full max-h-40 rounded-lg border border-gray-300 hidden object-contain" alt="Image Preview">
                    </div>
                    <!-- Voice Input -->
                    <div id="voice-control" class="flex flex-col items-center hidden">
                        <button id="mic-btn" class="flex items-center justify-center w-full py-2 px-4 bg-red-500 text-white font-semibold rounded-lg hover:bg-red-600 transition disabled:opacity-50">
                            <i data-lucide="mic" id="mic-icon" class="w-5 h-5 mr-2"></i>
                            <span id="mic-text">Click to Speak</span>
                        </button>
                        <p id="mic-status" class="text-xs text-gray-500 mt-1"></p>
                        <p id="voice-tip" class="text-xs text-indigo-600 mt-2 p-2 bg-indigo-100 rounded-md">
                            <i data-lucide="info" class="w-3 h-3 inline mr-1"></i>
                            The mic stays open longer to prevent "no-speech" errors, but for best accuracy in Indian languages, use Text mode.
                        </p>
                    </div>
                </div>

            </div>

            <!-- Output Card -->
            <div class="bg-emerald-50 p-4 rounded-xl border border-emerald-200 output-container flex flex-col relative">
                <div class="flex justify-between items-center mb-2">
                    <label class="font-bold text-emerald-700">Translation Output</label>
                    <button id="speak-btn" class="text-gray-500 hover:text-emerald-500 transition duration-150 p-1 rounded-full bg-emerald-100/50 hover:bg-emerald-100 disabled:opacity-50" disabled>
                        <i data-lucide="volume-2" class="w-5 h-5"></i>
                    </button>
                </div>
                <div id="output-text" class="flex-grow p-3 text-gray-800 bg-white rounded-lg overflow-y-auto">
                    Your translation will appear here.
                </div>
                <div id="audio-player-container" class="mt-3 hidden">
                    <audio id="audio-player" controls class="w-full"></audio>
                    <p class="text-xs text-emerald-700 mt-1">
                        <i data-lucide="gem" class="w-3 h-3 inline mr-1"></i>High-Quality Gemini Voice
                    </p>
                </div>

                <div id="loading-indicator" class="absolute inset-0 bg-white/70 backdrop-blur-sm flex items-center justify-center rounded-xl hidden">
                    <div class="text-center">
                        <i data-lucide="loader-circle" class="w-8 h-8 animate-spin text-indigo-600 mx-auto"></i>
                        <p class="mt-2 text-indigo-600 font-medium">Lingofy is processing...</p>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Translate Button -->
        <button id="translate-btn" class="translate-button w-full mt-6 py-3 px-6 bg-indigo-600 text-white font-bold rounded-lg text-lg hover:bg-indigo-700 focus:outline-none focus:ring-4 focus:ring-indigo-300 transition-colors duration-200">
            Start Translation
        </button>

        <!-- Message Box -->
        <div id="message-box" class="mt-4 p-3 bg-yellow-100 text-yellow-800 rounded-lg border border-yellow-300 hidden"></div>
    </div>

    <script>
        // --- Global Constants and Initialization ---
        
        // Canvas Global Variables (MUST be accessed safely)
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-lingofy-id';
        const firebaseConfig = typeof __firebase_config !== 'undefined' ? JSON.parse(__firebase_config) : null;
        const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null;

        const API_KEY = ""; // Canvas environment will inject the key
        const TEXT_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${API_KEY}`;
        const TTS_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${API_KEY}`;
        
        const SYSTEM_PROMPT = "You are a professional, high-quality, and fast translation engine. Ensure the translation is accurate and preserves the original meaning and tone.";

        // Expanded Language List including Indian Languages
        const LANGUAGES = [
            { code: 'en', name: 'English', voiceCode: 'en-US' },
            { code: 'hi', name: 'Hindi', voiceCode: 'hi-IN' },
            { code: 'mr', name: 'Marathi', voiceCode: 'mr-IN' },
            { code: 'ta', name: 'Tamil', voiceCode: 'ta-IN' },
            { code: 'es', name: 'Spanish', voiceCode: 'es-US' },
            { code: 'fr', name: 'French', voiceCode: 'fr-FR' },
            { code: 'de', name: 'German', voiceCode: 'de-DE' },
            { code: 'ja', name: 'Japanese', voiceCode: 'ja-JP' },
            { code: 'ko', name: 'Korean', voiceCode: 'ko-KR' },
            { code: 'pt', name: 'Portuguese', voiceCode: 'pt-BR' },
            { code: 'it', name: 'Italian', voiceCode: 'it-IT' },
            { code: 'zh-CN', name: 'Mandarin Chinese', voiceCode: 'zh-CN' }
        ];
        
        // Gemini Voice Mapping (one voice per language code)
        const GEMINI_VOICES = {
            'en': 'Zephyr', 'hi': 'Pulcherrima', 'mr': 'Sadaltager', 'ta': 'Sadachbia', 
            'es': 'Leda', 'fr': 'Puck', 'de': 'Charon', 'ja': 'Kore', 
            'ko': 'Fenrir', 'pt': 'Iapetus', 'it': 'Achernar', 'zh-CN': 'Orus'
        }

        // --- State Management ---
        let currentMode = 'text'; 
        let imageBase64 = null;
        let isTranslating = false;
        let db, auth;
        let userId = 'loading'; 
        let recognizer = null; // Speech Recognition instance
        let recognitionActive = false; // Tracks if the user *intends* the mic to be listening
        let currentStats = { total: 0, streak: 0 };


        // --- UI Elements ---
        const ui = {
            sourceLang: document.getElementById('source-lang'),
            targetLang: document.getElementById('target-lang'),
            inputText: document.getElementById('input-text'),
            outputText: document.getElementById('output-text'),
            translateBtn: document.getElementById('translate-btn'),
            swapBtn: document.getElementById('swap-btn'),
            speakBtn: document.getElementById('speak-btn'),
            loadingIndicator: document.getElementById('loading-indicator'),
            messageBox: document.getElementById('message-box'),
            charCount: document.getElementById('char-count'),
            modeText: document.getElementById('mode-text'),
            modeImage: document.getElementById('mode-image'),
            modeVoice: document.getElementById('mode-voice'),
            imageControl: document.getElementById('image-control'),
            voiceControl: document.getElementById('voice-control'),
            imageUpload: document.getElementById('image-upload'),
            imagePreview: document.getElementById('image-preview'),
            audioContainer: document.getElementById('audio-player-container'),
            audioPlayer: document.getElementById('audio-player'),
            micBtn: document.getElementById('mic-btn'),
            micText: document.getElementById('mic-text'),
            micIcon: document.getElementById('mic-icon'),
            micStatus: document.getElementById('mic-status'),
            voiceTip: document.getElementById('voice-tip'),
            inputLabel: document.getElementById('input-label'),
            totalTranslations: document.getElementById('total-translations'),
            currentStreak: document.getElementById('current-streak'),
            userIdDisplay: document.getElementById('user-id')
        };

        // --- Firebase/Firestore Functions (unchanged) ---

        /** Initializes Firebase and sets up authentication. */
        async function initializeFirebase() {
            if (!firebaseConfig) {
                console.error("Firebase config is missing.");
                return;
            }
            try {
                firebase.setLogLevel('Debug');
                const app = firebase.initializeApp(firebaseConfig);
                db = firebase.getFirestore(app);
                auth = firebase.getAuth(app);

                if (initialAuthToken) {
                    await firebase.signInWithCustomToken(auth, initialAuthToken);
                } else {
                    await firebase.signInAnonymously(auth);
                }

                firebase.onAuthStateChanged(auth, (user) => {
                    if (user) {
                        // Use user UID if authenticated, otherwise fallback to a random UUID
                        userId = user.uid || crypto.randomUUID();
                        ui.userIdDisplay.textContent = userId;
                        setupStatsListener(userId);
                    }
                });

            } catch (error) {
                console.error("Firebase Initialization/Auth Error:", error);
                showMessage("Database connection failed. Stats will not be saved.", 'error');
            }
        }

        /** Sets up a real-time listener for user stats. */
        function setupStatsListener(uid) {
            if (!db || !uid) return;

            const statsDocRef = firebase.doc(db, `artifacts/${appId}/users/${uid}/lingofy_stats/user_stats`);

            firebase.onSnapshot(statsDocRef, (doc) => {
                if (doc.exists()) {
                    currentStats = doc.data();
                    updateStatsUI();
                } else {
                    // Initialize stats if document doesn't exist
                    currentStats = { total: 0, streak: 0 };
                    updateStatsUI();
                    // Create the document immediately
                    firebase.setDoc(statsDocRef, currentStats, { merge: true }).catch(e => console.error("Error initializing stats doc:", e));
                }
            }, (error) => {
                console.error("Error listening to stats:", error);
                showMessage("Failed to load user stats from the database.", 'error');
            });
        }

        /** Updates the user's translation stats in Firestore. */
        async function updateStats(success) {
            if (!db || userId === 'loading') return;

            const statsDocRef = firebase.doc(db, `artifacts/${appId}/users/${userId}/lingofy_stats/user_stats`);
            let newStats = { ...currentStats };

            newStats.total += 1;
            if (success) {
                newStats.streak += 1;
            } else {
                newStats.streak = 0;
            }

            try {
                await firebase.setDoc(statsDocRef, newStats, { merge: true });
            } catch (error) {
                console.error("Error updating stats:", error);
                showMessage("Failed to save translation stats to the database.", 'error');
            }
        }

        /** Renders the current stats on the UI. */
        function updateStatsUI() {
            ui.totalTranslations.textContent = currentStats.total.toLocaleString();
            ui.currentStreak.textContent = currentStats.streak.toLocaleString();
        }

        // --- Utility Functions for TTS Conversion (unchanged) ---
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function pcmToWav(pcm16, sampleRate) {
            const buffer = new ArrayBuffer(44 + pcm16.length * 2);
            const view = new DataView(buffer);
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + pcm16.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, pcm16.length * 2, true);
            let offset = 44;
            for (let i = 0; i < pcm16.length; i++, offset += 2) {
                view.setInt16(offset, pcm16[i], true);
            }
            return new Blob([view], { type: 'audio/wav' });
        }

        function writeString(view, offset, str) {
            for (let i = 0; i < str.length; i++) {
                view.setUint8(offset + i, str.charCodeAt(i));
            }
        }

        // --- UI/Mode Functions (unchanged) ---

        /** Initializes the language selectors. */
        function initializeSelectors() {
            LANGUAGES.forEach(lang => {
                const sourceOption = new Option(lang.name, lang.code);
                const targetOption = new Option(lang.name, lang.code);
                ui.sourceLang.add(sourceOption);
                ui.targetLang.add(targetOption);
            });
            ui.sourceLang.value = 'en';
            ui.targetLang.value = 'es';
        }
        
        /** Displays a temporary message. */
        function showMessage(message, type = 'warning') {
            const baseClasses = "mt-4 p-3 rounded-lg border ";
            let typeClasses = "";
            switch (type) {
                case 'error': typeClasses = "bg-red-100 text-red-800 border-red-300"; break;
                case 'success': typeClasses = "bg-green-100 text-green-800 border-green-300"; break;
                case 'warning': default: typeClasses = "bg-yellow-100 text-yellow-800 border-yellow-300"; break;
            }
            ui.messageBox.className = baseClasses + typeClasses;
            ui.messageBox.textContent = message;
            ui.messageBox.classList.remove('hidden');
            setTimeout(() => { ui.messageBox.classList.add('hidden'); }, 5000);
        }

        /** Switches the application mode. */
        function switchMode(mode) {
            currentMode = mode;
            // Clear tab states
            [ui.modeText, ui.modeImage, ui.modeVoice].forEach(b => b.classList.remove('tab-active'));
            // Hide controls
            [ui.imageControl, ui.voiceControl].forEach(c => c.classList.add('hidden'));
            
            // Ensure mic is stopped if switching away from voice mode
            if (recognizer && recognitionActive) {
                recognizer.stop();
                recognitionActive = false;
            }

            // General setup
            ui.sourceLang.disabled = false;
            ui.inputText.disabled = false;
            ui.inputText.placeholder = "Type or use the file/voice input below...";
            ui.imagePreview.classList.add('hidden');
            // Do NOT clear text on mode switch, as user might want to translate transcribed text
            // ui.inputText.value = ''; 
            ui.voiceTip.classList.add('hidden'); // Hide tip by default

            // Mode specific setup
            if (mode === 'text') {
                ui.modeText.classList.add('tab-active');
                ui.translateBtn.textContent = 'Start Text Translation';
                ui.inputLabel.textContent = 'Enter Text';
            } else if (mode === 'image') {
                ui.modeImage.classList.add('tab-active');
                ui.imageControl.classList.remove('hidden');
                ui.sourceLang.value = 'en'; // Lock source to English for VLM input
                ui.sourceLang.disabled = true;
                ui.translateBtn.textContent = 'Analyze and Translate Image';
                ui.inputLabel.textContent = 'Image Upload';
                ui.inputText.disabled = true;
                showMessage("Source language locked to English for image analysis.", 'success');
            } else if (mode === 'voice') {
                ui.modeVoice.classList.add('tab-active');
                ui.voiceControl.classList.remove('hidden');
                ui.translateBtn.textContent = 'Translate Voice Input';
                ui.inputLabel.textContent = 'Voice Input';
                ui.inputText.placeholder = "Click the mic button to speak...";
                ui.voiceTip.classList.remove('hidden'); // Show tip for voice mode
                setupSpeechRecognition();
            }
            
            ui.outputText.textContent = "Your translation will appear here.";
            ui.audioContainer.classList.add('hidden'); 
            ui.speakBtn.disabled = true;
            updateCharCount();
        }

        /** Handles file selection and conversion for image mode. */
        function handleImageUpload(event) {
            const file = event.target.files[0];
            if (!file) return;

            if (file.size > 4 * 1024 * 1024) { 
                showMessage("Image file is too large (max 4MB).", 'error');
                ui.imageUpload.value = '';
                return;
            }

            const reader = new FileReader();
            reader.onloadend = () => {
                // Store the Base64 data (strip off the mime type header)
                imageBase64 = reader.result.split(',')[1]; 
                ui.imagePreview.src = reader.result;
                ui.imagePreview.classList.remove('hidden');
                showMessage("Image loaded successfully.", 'success');
            };
            reader.onerror = () => {
                showMessage("Failed to read image file.", 'error');
                imageBase64 = null;
            };
            reader.readAsDataURL(file);
        }

        /** Updates the character count display. */
        function updateCharCount() {
            const count = ui.inputText.value.length;
            ui.charCount.textContent = `${count} / 1000 characters`;
            if (count > 900) {
                ui.charCount.classList.add('text-red-500');
            } else {
                ui.charCount.classList.remove('text-red-500');
            }
        }

        // --- NEW/FIXED Speech Recognition Functions ---

        /** Initializes the Speech Recognition API with Continuous/Restart logic. */
        function setupSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window)) {
                ui.micBtn.disabled = true;
                ui.micText.textContent = "Speech Not Supported";
                showMessage("Your browser does not support Speech Recognition. Use Chrome or Edge.", 'error');
                return;
            }

            const SpeechRecognition = window.webkitSpeechRecognition;
            
            // Clean up old recognizer instance before creating a new one
            if (recognizer) {
                try { recognizer.stop(); } catch (e) { /* ignore InvalidStateError */ }
                recognizer = null;
            }
            
            recognizer = new SpeechRecognition();
            
            const selectedLang = LANGUAGES.find(l => l.code === ui.sourceLang.value);
            const voiceCode = selectedLang ? selectedLang.voiceCode : 'en-US';

            // *** FIX: Enable continuous listening to prevent 'no-speech' timeout ***
            recognizer.continuous = true; 
            recognizer.interimResults = true; // Use interim results for real-time feedback
            recognizer.lang = voiceCode; 
            
            ui.micStatus.textContent = `Language: ${selectedLang.name}. Click to start recording.`;

            recognizer.onstart = () => {
                ui.micText.textContent = "SPEAKING...";
                ui.micIcon.setAttribute('data-lucide', 'mic-off');
                lucide.createIcons();
                ui.micBtn.classList.add('recording-pulse');
                ui.micBtn.classList.replace('bg-red-500', 'bg-red-600');
                ui.micStatus.textContent = "Listening... speak now!";
                ui.inputText.disabled = true;
            };

            recognizer.onresult = (event) => {
                let finalTranscript = ui.inputText.value;
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Only update the main input with final text
                ui.inputText.value = finalTranscript.trim();
                
                // Show interim results in status for real-time feedback
                if (interimTranscript) {
                    ui.micStatus.textContent = `Listening: ${interimTranscript}...`;
                } else if (recognitionActive) {
                    ui.micStatus.textContent = "Listening... speak now!";
                }

                updateCharCount();
            };

            // *** FIX: Auto-restart the recognizer if it stops unexpectedly ***
            recognizer.onend = () => {
                ui.micIcon.setAttribute('data-lucide', 'mic');
                lucide.createIcons();
                ui.micBtn.classList.remove('recording-pulse');
                ui.micBtn.classList.replace('bg-red-600', 'bg-red-500');
                ui.inputText.disabled = false;

                if (recognitionActive) {
                    // It ended, but the user hasn't explicitly stopped it (recognitionActive is true)
                    // Wait a moment and restart to ensure continuous listening.
                    ui.micText.textContent = "Reconnecting...";
                    setTimeout(() => {
                        try {
                            recognizer.start();
                        } catch (e) {
                            if (e.name === 'InvalidStateError') {
                                // Ignore, already restarting
                            } else {
                                console.error("Auto-restart failed:", e);
                            }
                        }
                    }, 100); 
                } else {
                    // User explicitly stopped it
                    ui.micText.textContent = "Click to Speak";
                    ui.micStatus.textContent = "Recording stopped. Click 'Translate Voice Input'.";
                }
            };
            
            recognizer.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                
                let statusMessage = `Error: ${event.error}`;
                if (event.error === 'no-speech') {
                    statusMessage = "No speech detected (Retrying...).";
                }
                
                ui.micStatus.textContent = statusMessage;

                if (recognitionActive) {
                    // Restart on error if it was meant to be running
                    recognizer.stop(); // Ensure it's fully stopped before restarting
                } else {
                    showMessage(`Voice input error: ${event.error}. Please try again.`, 'error');
                }
            };
        }

        /** Toggles the speech recognition (Mic button click handler). */
        function toggleSpeechRecognition() {
            if (currentMode !== 'voice' || !recognizer) return;
            
            if (recognitionActive) {
                // Stop action
                recognitionActive = false;
                recognizer.stop(); 
            } else {
                // Start action
                ui.inputText.value = ''; // Clear text before recording
                recognitionActive = true;
                try {
                    recognizer.start();
                } catch (e) {
                    if (e.name === 'InvalidStateError') {
                        // Already listening (from an auto-restart), so just update UI state
                        ui.micStatus.textContent = "Already listening. Speak now!";
                    } else {
                        throw e;
                    }
                }
            }
        }

        // --- Translation Logic ---

        /** Calls the Gemini API for text or multimodal (image) translation. */
        async function handleTranslation() {
            if (isTranslating) return;

            let sourceText = ui.inputText.value.trim();
            let success = false;
            
            const sourceCode = ui.sourceLang.value;
            const targetCode = ui.targetLang.value;
            const sourceName = ui.sourceLang.options[ui.sourceLang.selectedIndex].text;
            const targetName = ui.targetLang.options[ui.targetLang.selectedIndex].text;

            // Stop recognition if it is active before translating
            if (currentMode === 'voice' && recognitionActive) {
                 recognitionActive = false;
                 recognizer.stop(); // This will trigger onend, which checks recognitionActive and won't restart
            }
            
            if (currentMode === 'text' || currentMode === 'voice') {
                if (!sourceText) {
                    showMessage("Please enter or speak some text to translate.");
                    return;
                }
            } 

            // Set UI to loading state
            isTranslating = true;
            ui.translateBtn.disabled = true;
            ui.speakBtn.disabled = true;
            ui.loadingIndicator.classList.remove('hidden');
            ui.outputText.textContent = "";
            ui.audioContainer.classList.add('hidden'); 

            let instruction;
            let contentParts = [];

            // --- Constructing the API Payload based on Mode ---
            if (currentMode === 'text' || currentMode === 'voice') {
                // *** CRITICAL FIX: Explicitly specify Source and Target codes in the prompt ***
                instruction = `Translate the following text from ${sourceName} (${sourceCode}) to ${targetName} (${targetCode}). Provide ONLY the exact, translated text, with no extra commentary.`;
                contentParts = [{ text: instruction }, { text: sourceText }];

            } else if (currentMode === 'image') {
                if (!imageBase64) {
                    showMessage("Please upload an image first.");
                    // Reset UI
                    isTranslating = false;
                    ui.translateBtn.disabled = false;
                    ui.loadingIndicator.classList.add('hidden');
                    return;
                }
                // For image, the instruction contains the context and the text content is null
                instruction = `Analyze the image. Extract any text found. Translate ONLY the extracted text into ${targetName} (${targetCode}). Respond ONLY with the translated text, nothing else.`;
                contentParts = [
                    { text: instruction }, 
                    {
                        inlineData: {
                            mimeType: ui.imageUpload.files[0].type || 'image/jpeg',
                            data: imageBase64
                        }
                    }
                ];
            }

            try {
                const payload = {
                    contents: [{ parts: contentParts }],
                    systemInstruction: { parts: [{ text: SYSTEM_PROMPT }] }
                };

                const response = await fetch(TEXT_API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`API returned status ${response.status}`);
                }

                const result = await response.json();
                const translatedText = result.candidates?.[0]?.content?.parts?.[0]?.text?.trim();

                if (translatedText) {
                    ui.outputText.innerHTML = translatedText;
                    ui.speakBtn.disabled = false;
                    success = true;
                    showMessage("Translation complete. Click the speaker icon for Gemini Voice!", 'success');
                } else {
                    ui.outputText.textContent = "Translation failed: Received empty content.";
                    showMessage("Could not get a clear translation. Try a clearer input.", 'error');
                }

            } catch (error) {
                console.error("Translation error:", error);
                ui.outputText.textContent = "Error: Failed to connect or process the translation.";
                showMessage(`A network error occurred: ${error.message}`, 'error');
            } finally {
                isTranslating = false;
                ui.translateBtn.disabled = false;
                ui.loadingIndicator.classList.add('hidden');
                updateStats(success); // Update stats regardless of success, tracking total attempts
            }
        }
        
        /** Uses the Gemini TTS API to generate and play high-quality speech. */
        async function handleTtsGeneration() {
            const textToSpeak = ui.outputText.textContent.trim();
            if (!textToSpeak || textToSpeak === "Your translation will appear here.") {
                showMessage("Nothing to speak. Please translate some text first.", 'warning');
                return;
            }

            ui.speakBtn.disabled = true;
            ui.audioContainer.classList.add('hidden');
            ui.translateBtn.disabled = true;
            
            showMessage("Generating high-fidelity audio...", 'warning');

            try {
                const targetCode = ui.targetLang.value;
                const voiceName = GEMINI_VOICES[targetCode] || 'Kore'; 
                
                const payload = {
                    contents: [{
                        parts: [{ text: `Say clearly: ${textToSpeak}` }]
                    }],
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: {
                            voiceConfig: {
                                prebuiltVoiceConfig: { voiceName: voiceName }
                            }
                        }
                    }
                };
                
                const response = await fetch(TTS_API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`TTS API returned status ${response.status}`);
                }
                
                const result = await response.json();
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType; 

                if (audioData && mimeType && mimeType.startsWith("audio/L16")) {
                    const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                    const sampleRate = sampleRateMatch ? parseInt(sampleRateMatch[1], 10) : 24000;
                    
                    const pcmData = base64ToArrayBuffer(audioData);
                    const pcm16 = new Int16Array(pcmData);
                    
                    const wavBlob = pcmToWav(pcm16, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    ui.audioPlayer.src = audioUrl;
                    ui.audioContainer.classList.remove('hidden');
                    ui.audioPlayer.play();
                } else {
                    showMessage("TTS failed: Audio data not received or invalid format.", 'error');
                }

            } catch (error) {
                console.error("TTS Generation error:", error);
                showMessage(`TTS Error: ${error.message}.`, 'error');
            } finally {
                ui.speakBtn.disabled = false;
                ui.translateBtn.disabled = false;
            }
        }

        /** Swaps the selected source and target languages. */
        function swapLanguages() {
            if (currentMode === 'image') {
                showMessage("Source language is locked in Image Mode.", 'warning');
                return;
            }
            const sourceValue = ui.sourceLang.value;
            const targetValue = ui.targetLang.value;

            ui.swapBtn.classList.add('animate-spin-once');
            setTimeout(() => {
                ui.sourceLang.value = targetValue;
                ui.targetLang.value = sourceValue;
                ui.swapBtn.classList.remove('animate-spin-once');
                if (currentMode === 'voice') {
                     setupSpeechRecognition(); // Reinitialize recognizer with new source language
                }
            }, 300);
        }

        // --- Event Listeners and Initialization ---
        document.addEventListener('DOMContentLoaded', () => {
            // Initialize Lucide icons
            if (typeof lucide !== 'undefined') {
                lucide.createIcons();
            }

            initializeFirebase();
            initializeSelectors();
            switchMode('text'); // Start in text mode

            // Main interaction listeners
            ui.translateBtn.addEventListener('click', handleTranslation);
            ui.swapBtn.addEventListener('click', swapLanguages);
            ui.speakBtn.addEventListener('click', handleTtsGeneration);
            ui.inputText.addEventListener('input', updateCharCount);
            
            // Mode switch listeners
            ui.modeText.addEventListener('click', () => switchMode('text'));
            ui.modeImage.addEventListener('click', () => switchMode('image'));
            ui.modeVoice.addEventListener('click', () => switchMode('voice'));

            // Input specific listeners
            ui.imageUpload.addEventListener('change', handleImageUpload);
            ui.micBtn.addEventListener('click', toggleSpeechRecognition);
            
            // Re-initialize speech recognition whenever source language changes in voice mode
            ui.sourceLang.addEventListener('change', () => {
                if (currentMode === 'voice') setupSpeechRecognition();
            });
            
            updateCharCount();
        });
    </script>
</body>
</html>
